<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>fjavieralba.com</title><link>blog/</link><description></description><atom:link href="blog/feeds/nlp.rss.xml" rel="self"></atom:link><lastBuildDate>Thu, 01 Nov 2012 00:00:00 +0100</lastBuildDate><item><title>Basic Sentiment Analysis with Python</title><link>blog/basic-sentiment-analysis-with-python.html</link><description>&lt;p&gt;In this post I will try to give a very introductory view of some techniques that could be useful when you want to perform a basic analysis of opinions written in english.&lt;/p&gt;
&lt;p&gt;These techniques come 100% from experience in real-life projects. Don't expect a theoretical introduction of Sentiment Analysis and the multiple strategies out there to achieve opinion mining, this is only a practical example of applying some basic rules to extract the polarity (positive or negative) of a text.&lt;/p&gt;
&lt;p&gt;Let's start looking at an example opinion:&lt;/p&gt;
&lt;blockquote&gt;
&lt;em&gt;&amp;quot;What can I say about this place. The staff of the restaurant is nice and the eggplant is not bad. Apart from that, very uninspired food, lack of atmosphere and too expensive. I am a staunch vegetarian and was sorely dissapointed with the veggie options on the menu. Will be the last time I visit, I recommend others to avoid.&amp;quot;&lt;/em&gt;&lt;/blockquote&gt;
&lt;p&gt;As you can see, this is a mainly negative review about a restaurant.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;General or detailed sentiment&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes we only want an overall rating of the sentiment of the whole review. In other cases, we need a little more detail, and we want each negative or positive comment identified.&lt;/p&gt;
&lt;p&gt;This kind of detailed detection can be quite challenging. Sometimes the aspect is explicit. An example is the opinion &lt;em&gt;&amp;quot;very uninspired food&amp;quot;&lt;/em&gt;, where the criticized aspect is the food. In other cases, is implicit: the sentence &lt;em&gt;&amp;quot;too expensive&amp;quot;&lt;/em&gt; gives a negative opinion about the price without mentioning it.&lt;/p&gt;
&lt;p&gt;In this post I will focus on detecting the overall polarity of a review, leaving for later the identification of individual opinions on concrete aspects of the restaurant.
To compute the polarity of a review, I'm going to use an approach based on dictionaries and some basic algorithms.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A note about the dictionaries&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A dictionary is no more than a list of words that share a category. For example, you can have a dictionary for positive expressions, and another one for stop words.&lt;/p&gt;
&lt;p&gt;The design of the dictionaries highly depends on the concrete topic where you want to perform the opinion mining. Mining hotel opinions is quite different than mining laptops opinions. Not only the positive/negative expressions could be different but the context vocabulary is also quite distinct.&lt;/p&gt;
&lt;div class="section" id="defining-a-structure-for-the-text"&gt;
&lt;h2&gt;Defining a structure for the text&lt;/h2&gt;
&lt;p&gt;Before writing code, there is an important decision to make. Our code will have to interact with text, splitting, tagging, and extracting information from it.&lt;/p&gt;
&lt;p&gt;But what should be the &lt;em&gt;structure&lt;/em&gt; of our text?&lt;/p&gt;
&lt;p&gt;This is a key decision because it will determine our algorithms in some ways. We should decide if we want to differentiate sentences inside a a paragraph. We could define a sentence as a list of tokens. But what is a token? a string? a more complex structure? Note that we will want to assign tags to our token. Should we only allow one tag per-token or unlimited ones?&lt;/p&gt;
&lt;p&gt;Infinite options here. We could choose a very simple structure, for example, defining the text simply as a list of words. Or we could define a more elaborated structure carrying every possible attribute of a processed text (word lemmas, word forms, multiple taggings, inflections...)&lt;/p&gt;
&lt;p&gt;As usual, a compromise between these two extremes can be a good way to go.&lt;/p&gt;
&lt;p&gt;For the examples of this post, I'm going to use the following structure:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Each text is a list of sentences&lt;/li&gt;
&lt;li&gt;Each sentence is a list of tokens&lt;/li&gt;
&lt;li&gt;Each token is a tuple of three elements: a word form (the exact word that appeared in the text), a word lemma (a generalized version of the word), and a list of associated tags&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a structure type I've found quite useful. Is ready for some &amp;quot;advanced&amp;quot; processing (lemmatization, multiple tags) without being too complex (at least in Python).&lt;/p&gt;
&lt;p&gt;This is an example of a POS-tagged paragraph:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt; &lt;span class="p"&gt;[[(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;All&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;All&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;that&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;that&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;is&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;is&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;VBZ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;gold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;gold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;does&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;does&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;VBZ&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;not&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;not&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;RB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;glitter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;glitter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;VB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])],&lt;/span&gt;
&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Not&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Not&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;RB&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;all&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;all&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;those&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;those&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;DT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;who&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;who&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;WP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;wander&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;wander&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;NN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;are&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;are&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;VBP&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;lost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;lost&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;VBN&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="prepocessing-the-text"&gt;
&lt;h2&gt;Prepocessing the Text&lt;/h2&gt;
&lt;p&gt;Once we have decided the structural shape of your processed text, we can start writing some code to read, and pre-process this text. With pre-process I mean some common first steps in NLP such as: Tokenize, Split into sentences, and POS Tag.&lt;/p&gt;
&lt;p&gt;I will use the NLTK library for these tasks:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3968990.js?file=splitter_postagger_nltk.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;Now, using this two simple wrapper classes, I can perform a basic text preprocessing, where the input is the text as a string and the output is a collection of sentences, each of which is again a collection of tokens.&lt;/p&gt;
&lt;p&gt;By the moment, our tokens are quite simple. Since we are using NLTK, and it does not lemmatize words, our forms and lemmas will be always identical. At this point of the process, the only tag associated to each word is its own POS Tag provided by NLTK.&lt;/p&gt;

        &lt;script src="https://gist.github.com/3968990.js?file=preprocessing_text.py"&gt;
        &lt;/script&gt;
        &lt;/div&gt;
&lt;div class="section" id="defining-a-dictionary-of-positive-and-negative-expressions"&gt;
&lt;h2&gt;Defining a dictionary of positive and negative expressions&lt;/h2&gt;
&lt;p&gt;The next step is to recognize positive and negative expressions. To achieve this, I'm going to use dictionaries, i.e. simple files containing expressions that will be searched in our text.&lt;/p&gt;
&lt;p&gt;For example, I'm going to define two tiny dictionaries, one for positive expressions and other for negative ones:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;positive.yml&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;nice&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;positive&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;awesome&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;positive&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;cool&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;positive&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;superb&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;positive&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;negative.yml&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;bad&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;negative&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;uninspired&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;negative&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;expensive&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;negative&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;dissapointed&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;negative&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;recommend others to avoid&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;negative&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In case you were wondering, we could have used a simpler format, or used only one file, but this dictionary format will be useful later.&lt;/p&gt;
&lt;p&gt;Note that these are only two example dictionaries, useless in a real life project.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tagging-the-text-with-dictionaries"&gt;
&lt;h2&gt;Tagging the text with dictionaries&lt;/h2&gt;
&lt;p&gt;The following code defines a class that I will use to tag our pre-processed text with our just defined dictionaries.&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969016.js?file=dictionary_tagger.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;When tagging our review, the input is the previously preprocessed text, and the output is the same text, enriched with tags of type &amp;quot;positive&amp;quot; or &amp;quot;negative&amp;quot;:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969016.js?file=tagging_positive_negative.py"&gt;
        &lt;/script&gt;
        &lt;/div&gt;
&lt;div class="section" id="a-simple-sentiment-measure"&gt;
&lt;h2&gt;A simple sentiment measure&lt;/h2&gt;
&lt;p&gt;We could already perform a basic calculus of the positiveness or negativeness of a review.&lt;/p&gt;
&lt;p&gt;Simply counting how many positive and negative expressions we detected, could be a (very naive) sentiment measure.&lt;/p&gt;
&lt;p&gt;The following code snippet applies this idea:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969825.js?file=basic_sentiment_score.py"&gt;
        &lt;/script&gt;
        
        &lt;script src="https://gist.github.com/3969825.js?file=example_exec_1.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;So, our review could be considered &amp;quot;quite negative&amp;quot; since it has a score of -4&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="incrementers-and-decrementers"&gt;
&lt;h2&gt;Incrementers and decrementers&lt;/h2&gt;
&lt;p&gt;The previous &amp;quot;sentiment score&amp;quot; was very basic: it only counts positive and negative expressions and makes a sum, without taking into account that maybe some expressions are more positive or more negative than others.&lt;/p&gt;
&lt;p&gt;A way of defining this &amp;quot;strength&amp;quot; could be using two new dictionaries. One for &amp;quot;incrementers&amp;quot; and another for &amp;quot;decrementers&amp;quot;.&lt;/p&gt;
&lt;p&gt;Let's define two tiny examples:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;inc.yml&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;too&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;inc&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;very&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;inc&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;sorely&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;inc&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;dec.yml&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;barely&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;dec&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;little&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;dec&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We instantiate again our tagger, telling it to use these two new dictionaries:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969016.js?file=tagging_inc_dec.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;Now, we could improve in some way our sentiment score. The idea is that &amp;quot;good&amp;quot; has more strength than &amp;quot;barely good&amp;quot; but less than &amp;quot;very good&amp;quot;.&lt;/p&gt;
&lt;p&gt;The following code defines the recursive function &lt;tt class="docutils literal"&gt;sentence_score&lt;/tt&gt; to compute the sentiment score of a sentence.
The most remarkable thing about it is that it uses information about the previous token to make a decision on the score of the current token.&lt;/p&gt;
&lt;p&gt;This function is then used by our new &lt;tt class="docutils literal"&gt;sentiment_score&lt;/tt&gt; function:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969825.js?file=sentiment_score_inc_dec.py"&gt;
        &lt;/script&gt;
        
        &lt;script src="https://gist.github.com/3969825.js?file=example_exec_2.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;Notice that the review is now considered more negative, due to the appearance of expressions such as &amp;quot;very uninspired&amp;quot;, &amp;quot;too expensive&amp;quot; and &amp;quot;sorely dissapointed&amp;quot;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="inverters-and-polarity-flips"&gt;
&lt;h2&gt;Inverters and polarity flips&lt;/h2&gt;
&lt;p&gt;With the approach we've been following so far, some expressions could be incorrectly tagged.
For example, this part of our example review:&lt;/p&gt;
&lt;blockquote&gt;
&lt;em&gt;the eggplant is not bad&lt;/em&gt;&lt;/blockquote&gt;
&lt;p&gt;contains the word &lt;em&gt;bad&lt;/em&gt; but the sentence is a positive opinion about the eggplant.&lt;/p&gt;
&lt;p&gt;This is because the appearance of the negation word &lt;em&gt;not&lt;/em&gt;, that flips the meaning of the negative adjective &lt;em&gt;bad&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We could take into account these types of polarity flips defining a dictionary of inverters:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;inv.yml&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;lack of&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;inv&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;not&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="p-Indicator"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;inv&lt;/span&gt;&lt;span class="p-Indicator"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When tagging our text, we should also specify this new dictionary in the instantiation of our tagger:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969016.js?file=tagging_inverters.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;Then, we could adapt our sentiment_score function. We want it to flip the polarity of a sentiment word when is preceded by an inverter:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969825.js?file=sentiment_score_flips.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;Recalculating again the sentiment score:&lt;/p&gt;

        &lt;script src="https://gist.github.com/3969825.js?file=example_exec_3.py"&gt;
        &lt;/script&gt;
        &lt;p&gt;It's now -5.0 since &amp;quot;not bad&amp;quot; is considered positive.&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">F. Javier Alba</dc:creator><pubDate>Thu, 01 Nov 2012 00:00:00 +0100</pubDate><guid>tag:blog,2012-11-01:basic-sentiment-analysis-with-python.html</guid><category>python</category><category>nlp</category><category>sentiment analysis</category></item></channel></rss>